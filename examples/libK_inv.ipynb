{
  "cells": [
    {
      "cell_type": "raw",
      "id": "ac7c368c",
      "metadata": {
        "id": "ac7c368c"
      },
      "source": [
        "title: \"SUR / update_simulate / inv\"\n",
        "\n",
        "authors: \"IRSN / Y. Richet, IFPEN / M. Menz, M. Munoz-Zuniga\"\n",
        "\n",
        "date: \"2024-11-14\"\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c427d514",
      "metadata": {
        "id": "c427d514"
      },
      "outputs": [],
      "source": [
        "# Installation des packages nécessaires, en utilisant packagemanager.posit pour accélérer\n",
        "options(repos=list(CRAN='https://packagemanager.posit.co/cran/__linux__/jammy/latest/'))\n",
        "install.packages('rlibkriging')\n",
        "install.packages('DiceView')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Latest DiceView (waiting for CRAN sync)\n",
        "remotes::install_github('IRSN/DiceView')"
      ],
      "metadata": {
        "id": "3sW7Yv8sy_Zd"
      },
      "id": "3sW7Yv8sy_Zd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abc9444e",
      "metadata": {
        "id": "abc9444e"
      },
      "outputs": [],
      "source": [
        "#knitr::opts_chunk$set(echo = TRUE)\n",
        "\n",
        "# chargement des librairies\n",
        "library(rlibkriging)\n",
        "library(DiceView)\n",
        "\n",
        "# setup default plots aesthetics\n",
        "par(oma = c(0,0,0,0))\n",
        "par(mar = c(3, 3, 1, 1))\n",
        "par(cex.lab=0.5, cex.axis=0.5, cex.main=0.5)\n",
        "par(bg = \"white\")\n",
        "\n",
        "options(digits=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fee51a3d",
      "metadata": {
        "id": "fee51a3d"
      },
      "source": [
        "# Objectif\n",
        "\n",
        "On cherche à trouver la zone de dépassement de la valeur $t=0.8$ pour la fonction\n",
        "$$f: x \\rightarrow     1 - (sin(12  x) / (1 + x) + 2 cos(7 x)  x^5 + 0.7) / 2$$\n",
        "\n",
        "Soit, identifier\n",
        "$$I := \\{x \\in D_X : f(x) > t \\}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7e93399",
      "metadata": {
        "id": "f7e93399"
      },
      "outputs": [],
      "source": [
        "f <- function(x)\n",
        "    1 - (sin(12 * x) / (1 + x) + 2 * cos(7 * x) * x^5 + 0.7) / 2\n",
        "\n",
        "plot(f)\n",
        "\n",
        "abline(h = 0.8, col='red', lty=2)\n",
        "# On cherche à identifier I:\n",
        "I = sort(optims(c(0.3,0.4), function(x) (f(x) - 0.8)^2, method=\"L-BFGS-B\", lower=0, upper=1)$pars)\n",
        "polygon(c(I,rev(I)), c(0,0,1.1,1.1), col=rgb(1,0,0,.2), border=NA)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c401447",
      "metadata": {
        "id": "5c401447"
      },
      "source": [
        "# Métamodèle GP\n",
        "\n",
        "Sur un plan d'expérience inital réduit $(X_0,Y_0)$, on construit un processus gaussien dont le prédicteur est :\n",
        "$$\\xi_{X_0,Y_0}: x \\rightarrow \\xi(x) \\sim \\mathcal N(m_{X_0,Y_0}(x),k_{X_0,Y_0}(x))$$\n",
        "\n",
        "Ce méta-modèle est insuffisant en l'état pour atteindre l'objectif :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e62383af",
      "metadata": {
        "id": "e62383af"
      },
      "outputs": [],
      "source": [
        "# plan d'exp initial\n",
        "X0 = matrix(c(.2,.4,.6,.8),ncol=1)\n",
        "Y0 = f(X0)\n",
        "\n",
        "sectionview(f, dim=1, col='black', Xlim=c(0,1),ylim=c(-.2,1.2))\n",
        "points(X0, Y0)\n",
        "\n",
        "GP = function(X,Y)\n",
        "  Kriging(matrix(Y), matrix(X), kernel=\"gauss\", optim=\"none\", parameters=list(theta=c(.15),sigma2=1))\n",
        "\n",
        "sectionview(GP(X0,Y0), conf_level=0.9, col='blue', add=TRUE)\n",
        "\n",
        "# Objectif\n",
        "abline(h=0.8, col='red',lty=3)\n",
        "polygon(c(I,rev(I)), c(-0.3,-0.3,1.3,1.3), col=rgb(1,0,0,.2), border=NA)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d25a5532",
      "metadata": {
        "id": "d25a5532"
      },
      "source": [
        "# Dépassement de seuil y > 0.8 du métamodèle\n",
        "\n",
        "Soit $X,Y$ notre plan d'expériences courant (pour le moment initial).\n",
        "\n",
        "Choix du critère \"local\" d'intérêt : MSE de classification wrt. 0.8\n",
        "\n",
        "On calcule le critère \"global\" $J$ en utilisant les prédictions du GP courant $\\xi$ et en intégrant numériquement le critère sur $D_X$ :\n",
        "\n",
        "$$J_{X,Y} := \\int_{x \\in D_X} P[\\xi_{X,Y}(x)>t] (1-P[\\xi_{X,Y}(x)>t]) $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12cb2f77",
      "metadata": {
        "id": "12cb2f77"
      },
      "outputs": [],
      "source": [
        "x = seq(0, 1,,101)\n",
        "\n",
        "X = X0\n",
        "Y = Y0\n",
        "\n",
        "# predictions du métamodèle\n",
        "y = GP(X,Y)$predict(x)\n",
        "\n",
        "# proba de dépassement de 0.8\n",
        "P = 1-pnorm(0.8,y$mean,y$stdev)\n",
        "\n",
        "par(mfrow=c(3,1))\n",
        "\n",
        "sectionview(GP(X,Y), Xlim=c(0,1),ylim=c(-.2,1.2), conf_lev=.9)\n",
        "# Objectif\n",
        "abline(h=0.8, col='red',lty=3)\n",
        "polygon(c(I,rev(I)), c(-0.3,-0.3,1.3,1.3), col=rgb(1,0,0,.2), border=NA)\n",
        "\n",
        "plot(x,P, type='l',col='violet', main=\"Proba de dépassement de 0.8\")\n",
        "abline(h=0.5)\n",
        "# Objectif\n",
        "polygon(c(I,rev(I)), c(-0.3,-0.3,1.3,1.3), col=rgb(1,0,0,.2), border=NA)\n",
        "\n",
        "plot(x,P*(1-P), type='l',col='violet', main=\"Erreur (quad.) de classification wrt. 0.8\")\n",
        "polygon(c(0,x,1), c(0,P*(1-P),0), col=rgb(1,0.5,1,.2), border=NA)\n",
        "# Objectif\n",
        "polygon(c(I,rev(I)), c(-0.3,-0.3,1.3,1.3), col=rgb(1,0,0,.2), border=NA)\n",
        "\n",
        "# J: intégrale sur X de l'erreur quad. de classif.\n",
        "text(x=.5,y=.1,labels=paste0(\"J = \",sum(P * (1-P))/length(P)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5ad20a6",
      "metadata": {
        "id": "e5ad20a6"
      },
      "source": [
        "\n",
        "\n",
        "Une alternative consiste en un calcul empirique utilisant les simulations du GP (et non pas les prédictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8e6b5d3",
      "metadata": {
        "id": "c8e6b5d3"
      },
      "outputs": [],
      "source": [
        "# simulations du métamodèle\n",
        "S = GP(X,Y)$simulate(nsim=100,seed=123, x)\n",
        "\n",
        "# proba (empirique) de dépassement de 0.8\n",
        "P_S = rowSums(S>0.8)/ncol(S)\n",
        "\n",
        "par(mfrow=c(3,1))\n",
        "\n",
        "sectionview(GP(X,Y), Xlim=c(0,1),ylim=c(-.2,1.2), conf_lev=.9, conf_fading = 0.1)\n",
        "for (i in 1:ncol(S))\n",
        "    lines(x,S[,i], col=rgb(0,0,1,.21),lty=1)\n",
        "# Objectif\n",
        "abline(h=0.8, col='red',lty=3)\n",
        "polygon(c(I,rev(I)), c(-0.3,-0.3,1.3,1.3), col=rgb(1,0,0,.2), border=NA)\n",
        "\n",
        "plot(x,P_S, type='l',col='violet', main=\"Proba de dépassement de 0.8\")\n",
        "lines(x,P, lty=2,col='violet')\n",
        "abline(h=0.5)\n",
        "# Objectif\n",
        "polygon(c(I,rev(I)), c(-0.3,-0.3,1.3,1.3), col=rgb(1,0,0,.2), border=NA)\n",
        "\n",
        "plot(x,P_S*(1-P_S), type='l',col='violet', main=\"Erreur (quad.) de classification wrt. 0.8\")\n",
        "lines(x,P*(1-P), lty=2,col='violet')\n",
        "polygon(c(0,x,1), c(0,P_S*(1-P_S),0), col=rgb(1,0.5,1,.2), border=NA)\n",
        "# Objectif\n",
        "polygon(c(I,rev(I)), c(-0.3,-0.3,1.3,1.3), col=rgb(1,0,0,.2), border=NA)\n",
        "\n",
        "# J: intégrale sur X de l'erreur quad. de classif.\n",
        "text(x=.5,y=.1,labels=paste0(\"Ĵ = \",sum(P_S * (1-P_S))/length(P_S)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cb8e0f7",
      "metadata": {
        "id": "3cb8e0f7"
      },
      "source": [
        "# Recherche d'un nouveau point de design \"informatif\"\n",
        "\n",
        "Critère d'intérêt \"intégrale erreur (quad.) de classification\" :\n",
        "$$J(X,Y) = \\int_{x \\in D_X} P[\\xi_{X,Y}(x)>t] (1-P[\\xi_{X,Y}(x)>t])$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11ed854d",
      "metadata": {
        "id": "11ed854d"
      },
      "outputs": [],
      "source": [
        "J = function(X,Y) {\n",
        "    y = GP(X,Y)$predict(x)\n",
        "    P = 1 - pnorm(0.8,y$mean,y$stdev)\n",
        "    return( mean( P*(1-P) ) )\n",
        "}\n",
        "J(X,Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d46acd1d",
      "metadata": {
        "id": "d46acd1d"
      },
      "source": [
        "---\n",
        "#Démarche \"SUR\"\n",
        "Nous cherchons à placer un point de design qui ajouté au plan d'expériences,\n",
        "$$({X \\cup x_{next}},{Y \\cup y_{next}}),$$\n",
        "va minimiser notre critère global :\n",
        "$$J({X \\cup x_{next}},{Y \\cup y_{next}})$$\n",
        "En supposant que les valeurs $y_{next}$ sont des réalisations de $\\xi_{X,Y}(x_{next})$, le GP courant, nous introduisons l'amélioration espérée correspondante :\n",
        "\n",
        "$$J_{next}(x_{next}) = E_{\\xi(x_{next})} \\big[J({X \\cup x_{next}},{Y \\cup \\xi(x_{next})}\\big].$$\n",
        "\n",
        "---\n",
        "\n",
        "Soit,\n",
        "\n",
        "$$J_{next}(x_{next}) = \\int_{y_{next} \\sim \\xi(x_{next})} \\int_{x \\in D_X} P[\\xi_{X\\cup x_{next},Y\\cup y_{next}}(x)>t] (1-P[\\xi_{X\\cup x_{next},Y\\cup y_{next}}(x)>t])$$\n",
        "\n",
        "# Evaluation du gain de $J$ en ajoutant $x_{next}$ supplémentaire au design\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dfeea28",
      "metadata": {
        "id": "2dfeea28"
      },
      "outputs": [],
      "source": [
        "#split.screen(figs = c(2,1))\n",
        "\n",
        "#screen(1, new=TRUE)\n",
        "plot(f, xlim=c(0.2,0.8), ylim=c(-0.3,1.3))\n",
        "sectionview(GP(X,Y), conf_lev=.9, conf_fading = 0.5, Xlim=c(0,1), ylim=c(-0.3,1.3), add=TRUE)\n",
        "# Objectif\n",
        "abline(h=0.8, col='red',lty=3)\n",
        "#polygon(c(I,rev(I)), c(-0.3,-0.3,1.3,1.3), col=rgb(1,0,0,.2), border=NA)\n",
        "\n",
        "#screen(2, new=TRUE)\n",
        ".x=seq(0,1,,1001)\n",
        "p.x = pnorm(0.8, GP(X,Y)$predict(.x)$mean, GP(X,Y)$predict(.x)$stdev)\n",
        "#lines(.x,p.x*(1-p.x), type='l',col='blue')\n",
        "polygon(c(0,.x,1), c(0,p.x*(1-p.x),0)-0.3, col=rgb(0,0,1,.2), border=NA)\n",
        "text(x=.5,y=.1,col=\"blue\",labels=paste0(\"J = \",J(X,Y)))\n",
        "\n",
        "# choix arbitraire du point de design suivant\n",
        "xnext = x[31] # =0.3\n",
        "#screen(1, new=FALSE)\n",
        "abline(v=xnext,col='red')\n",
        "\n",
        "# calcul du SUR avec ce point\n",
        "Ynext = GP(X,Y)$predict(xnext)\n",
        "\n",
        "Jnext = array(NA,5)\n",
        "for (i in 1:length(Jnext)) { # on échantillone ynext selon la loi de prédiction en xnext (normale)\n",
        "    q = i/(length(Jnext)+1)\n",
        "    ynext_i = qnorm(q, Ynext$mean, Ynext$stdev)\n",
        "    jnext_i = J(c(X,xnext),c(Y,ynext_i))\n",
        "    Jnext[i] = jnext_i\n",
        "\n",
        "    GPnext_i = GP(c(X,xnext),c(Y,ynext_i))\n",
        "    #screen(1, new=FALSE)\n",
        "    sectionview(GPnext_i, col=\"violet\", conf_lev=.9, conf_fading = 0.5, Xlim=c(0,1), add=TRUE)\n",
        "\n",
        "    #screen(2, new=FALSE)\n",
        "    p.x = pnorm(0.8, GPnext_i$predict(.x)$mean, GPnext_i$predict(.x)$stdev)\n",
        "    #lines(.x,p.x*(1-p.x),col='violet')\n",
        "    polygon(c(0,.x,1), c(0,p.x*(1-p.x),0)-0.3, col=rgb(1,0.5,1,.2), border=\"violet\")\n",
        "}\n",
        "text(x=xnext,y=.1,col=\"violet\",labels=paste0(\"Jnext(\",xnext,\") = \\n\",mean(Jnext)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e346e15e",
      "metadata": {
        "id": "e346e15e"
      },
      "source": [
        "# Calcul de Jnext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce471b0d",
      "metadata": {
        "id": "ce471b0d"
      },
      "outputs": [],
      "source": [
        "# calcul \"exact\" du SUR avec ce point\n",
        "Ynext = GP(X,Y)$predict(xnext)\n",
        "Jnext = integrate(Vectorize(function(q) # on échantillonne selon la loi (normale) de Kn en xnext\n",
        "    J(c(X,xnext),c(Y, qnorm(q, Ynext$mean, Ynext$stdev)))),\n",
        "    0 +1e-3, 1 -1e-3)$value\n",
        "print(paste0(\"Jnext(\",xnext,\")  = \",Jnext))\n",
        "\n",
        "# ... ou version approx. par mesh régulier des quantiles :\n",
        "Jnext = function(xnext, X, Y) {\n",
        "    if (any(abs(xnext-X)<1e-5)) { return(J(X,Y)) }\n",
        "    Ynext = GP(X,Y)$predict(xnext)\n",
        "    Jnext = array(NA,100)\n",
        "    for (i in 1:length(Jnext)) {\n",
        "        q = i/(length(Jnext)+1)\n",
        "        ynext_i = qnorm(q, Ynext$mean, Ynext$stdev)\n",
        "        Jnext[i] = J(c(X,xnext),c(Y,ynext_i))\n",
        "    }\n",
        "    return(mean(Jnext))\n",
        "}\n",
        "print(paste0(\"Jnext(\",xnext,\") ~= \",Jnext(xnext,X,Y)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55e9a39c",
      "metadata": {
        "id": "55e9a39c"
      },
      "source": [
        "# Critère local vs. global\n",
        "\n",
        "On peut comparer les deux approches \"locale\" $P (1-P)$ et \"globale\" $J_{next}$ de choix du prochain point de design :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3187ce1e",
      "metadata": {
        "id": "3187ce1e"
      },
      "outputs": [],
      "source": [
        "par(mfrow=c(3,1))\n",
        "\n",
        "sectionview(GP(X,Y), Xlim=c(0,1),ylim=c(-.2,1.2), conf_lev=.9)\n",
        "# Objectif\n",
        "abline(h=0.8, col='red',lty=3)\n",
        "polygon(c(I,rev(I)), c(-0.3,-0.3,1.3,1.3), col=rgb(1,0,0,.2), border=NA)\n",
        "\n",
        "\n",
        "# predictions du métamodèle\n",
        "y = GP(X,Y)$predict(x)\n",
        "\n",
        "# proba de dépassement de 0.8\n",
        "P = 1-pnorm(0.8,y$mean,y$stdev)\n",
        "\n",
        "plot(x,P*(1-P), type='l',col='violet', main=\"Erreur (quad.) de classification wrt. 0.8\")\n",
        "polygon(c(0,x,1), c(0,P*(1-P),0), col=rgb(1,0.5,1,.2), border=NA)\n",
        "# Objectif\n",
        "polygon(c(I,rev(I)), c(-0.3,-0.3,1.3,1.3), col=rgb(1,0,0,.2), border=NA)\n",
        "\n",
        "# meilleurs points (selon P(1-P)):\n",
        "P_opts = optims(seq(0,1,,11), function(x) {\n",
        "  y = GP(X,Y)$predict(x);\n",
        "  p=pnorm(0.8,y$mean,y$stdev);\n",
        "  -p*(1-p) }, method=\"L-BFGS-B\", lower=0, upper=1)\n",
        "P_opts = P_opts$pars[P_opts$values < 0]\n",
        "abline(v=P_opts,col='violet',lty=3)\n",
        "\n",
        "DJ_x = J(X,Y) - Vectorize(function(.x)Jnext(.x,X,Y))(x)\n",
        "plot(x,DJ_x, type='l',col='purple', main=\"SUR P(1-P) wrt. 0.8\")\n",
        "polygon(c(0,x,1), c(0,DJ_x,0), col=rgb(0.5,0,1,.2), border=NA)\n",
        "abline(v=P_opts,col='violet',lty=3)\n",
        "# Objectif\n",
        "polygon(c(I,rev(I)), c(-0.3,-0.3,1.3,1.3), col=rgb(1,0,0,.2), border=NA)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16852ada",
      "metadata": {
        "id": "16852ada"
      },
      "source": [
        "# Utilisation des simulations pour évaluer le critère Jnext"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e39a3a2",
      "metadata": {
        "id": "5e39a3a2"
      },
      "source": [
        "Fonction générique de calcul de $\\hat J(X,Y)$ à partir de simulations du processus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73fb4837",
      "metadata": {
        "id": "73fb4837"
      },
      "outputs": [],
      "source": [
        "J_hat = function(X,Y, nsim=100) {\n",
        "    #y = GP(X,Y)$predict(x)\n",
        "    S = GP(X,Y)$simulate(nsim=nsim,seed=123, x)\n",
        "    P = rowSums(S > 0.8)/ncol(S)\n",
        "    j = mean( P*(1-P) )\n",
        "    attributes(j) <- list(\"sd\" = sd(P*(1-P))/sqrt(nsim))\n",
        "    return(j)\n",
        "}\n",
        "t0 = Sys.time()\n",
        "print(paste0(\"Calcul avec les prédictions: J = \",J(X0,Y0)))\n",
        "print(Sys.time()-t0)\n",
        "\n",
        "t0 = Sys.time()\n",
        "Jhat = J_hat(X0,Y0, nsim=10000)\n",
        "print(paste0(\"Calcul avec les simulations: Ĵ = \",Jhat, \" +/- \",attributes(Jhat)$sd))\n",
        "print(Sys.time()-t0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65f10892",
      "metadata": {
        "id": "65f10892"
      },
      "source": [
        "On constate que l'utilisation des simulations (pour une précision élevée) est plus __lente__ que l'utilisation des prédictions.\n",
        "\n",
        "Utilisons l'approche par simulation pour la fonction générique de calcul de $\\hat J_{next}$ :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd1094ba",
      "metadata": {
        "id": "cd1094ba"
      },
      "outputs": [],
      "source": [
        "Jnext_hat = function(xnext, X,Y, nsim=100) {\n",
        "    if (any(abs(xnext-X)<1e-5)) { return(J_hat(X,Y)) }\n",
        "    Ynext = GP(X,Y)$predict(xnext)\n",
        "    Jnext = array(NA,100)\n",
        "    for (i in 1:length(Jnext)) { # on échantillone ynext selon la loi de prédiction en xnext (normale)\n",
        "        q = i/(length(Jnext)+1)\n",
        "        ynext_i = qnorm(q, Ynext$mean, Ynext$stdev)\n",
        "        Jnext[i] = J_hat(c(X,xnext),c(Y,ynext_i), nsim=nsim)\n",
        "    }\n",
        "    return(mean(Jnext))\n",
        "}\n",
        "t0 = Sys.time()\n",
        "print(paste0(\"Calcul avec les prédictions: Jnext(\",xnext,\") = \",Jnext(xnext,X0,Y0)))\n",
        "print(Sys.time()-t0)\n",
        "\n",
        "t0 = Sys.time()\n",
        "print(paste0(\"Calcul avec les simulations: Ĵnext(\",xnext,\") = \",Jnext_hat(xnext,X0,Y0, nsim=100)))\n",
        "print(Sys.time()-t0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2477e01",
      "metadata": {
        "id": "b2477e01"
      },
      "source": [
        "On optimise le calcul de $\\hat J_{next}$ en utilisant les updates de simulations du GP :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8df72eb",
      "metadata": {
        "id": "e8df72eb"
      },
      "outputs": [],
      "source": [
        "Jnext_hat_fast = function(xnext, X,Y, nsim=100) {\n",
        "    if (any(abs(xnext-X)<1e-5)) { return(J_hat(X,Y)) }\n",
        "    Ynext = GP(X,Y)$predict(xnext)\n",
        "    gp = GP(X,Y)\n",
        "    S = gp$simulate(nsim=nsim,seed=123, c(xnext,x), will_update=TRUE) # needed for later 'update_simulate'\n",
        "    Jnext = array(NA,100)\n",
        "    for (i in 1:length(Jnext)) { # on échantillone ynext selon la loi de prédiction en xnext (normale)\n",
        "        q = i/(length(Jnext)+1)\n",
        "        ynext_i = qnorm(q, Ynext$mean, Ynext$stdev)\n",
        "################################################################################\n",
        "        Snext_i = gp$update_simulate(ynext_i, xnext)\n",
        "################################################################################\n",
        "        P = rowSums(Snext_i>0.8)/ncol(Snext_i)\n",
        "        Jnext[i] = mean( P*(1-P) )\n",
        "    }\n",
        "    return(mean(Jnext))\n",
        "}\n",
        "t0 = Sys.time()\n",
        "print(paste0(\"Calcul avec les prédictions: Jnext(\",xnext,\") = \",Jnext(xnext,X0,Y0)))\n",
        "print(Sys.time()-t0)\n",
        "\n",
        "t0 = Sys.time()\n",
        "print(paste0(\"Calcul avec les simulations: Ĵnext(\",xnext,\") = \",Jnext_hat(xnext,X0,Y0, nsim=100)))\n",
        "print(Sys.time()-t0)\n",
        "\n",
        "t0 = Sys.time()\n",
        "print(paste0(\"Calcul avec les simulations updatées: Ĵnextup(\",xnext,\") = \",Jnext_hat_fast(xnext,X0,Y0, nsim=100)))\n",
        "print(Sys.time()-t0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d40da440",
      "metadata": {
        "id": "d40da440"
      },
      "source": [
        "On peut finalement comparer ces différentes versions du critère $J_{next}$ :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55bec5be",
      "metadata": {
        "id": "55bec5be"
      },
      "outputs": [],
      "source": [
        "par(mfrow=c(3,1))\n",
        "\n",
        "DJ_x = J(X,Y) - Vectorize(function(.x)Jnext(.x,X,Y))(x)\n",
        "plot(x,DJ_x, type='l',col='purple', main=\"SUR P(1-P) wrt. 0.8 (predict)\")\n",
        "polygon(c(0,x,1), c(0,DJ_x,0), col=rgb(0.5,0,1,.2), border=NA)\n",
        "# Objectif\n",
        "polygon(c(I,rev(I)), c(-0.3,-0.3,1.3,1.3), col=rgb(1,0,0,.2), border=NA)\n",
        "\n",
        "DJ_hat_x = J_hat(X,Y) - Vectorize(function(.x)Jnext_hat(.x,X,Y,nsim=100))(x)\n",
        "plot(x,DJ_hat_x, type='l',col='purple', main=\"SUR P(1-P) wrt. 0.8 (simulate)\")\n",
        "polygon(c(0,x,1), c(0,DJ_hat_x,0), col=rgb(0.5,0,1,.2), border=NA)\n",
        "# Objectif\n",
        "polygon(c(I,rev(I)), c(-0.3,-0.3,1.3,1.3), col=rgb(1,0,0,.2), border=NA)\n",
        "\n",
        "DJ_hat_fast_x = J_hat(X,Y) - Vectorize(function(.x)Jnext_hat_fast(.x,X,Y,nsim=100))(x)\n",
        "plot(x,DJ_hat_fast_x, type='l',col='purple', main=\"SUR P(1-P) wrt. 0.8 (update simulate)\")\n",
        "polygon(c(0,x,1), c(0,DJ_hat_fast_x,0), col=rgb(0.5,0,1,.2), border=NA)\n",
        "# Objectif\n",
        "polygon(c(I,rev(I)), c(-0.3,-0.3,1.3,1.3), col=rgb(1,0,0,.2), border=NA)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "jupytext": {
      "cell_metadata_filter": "eval,-all",
      "main_language": "R",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}